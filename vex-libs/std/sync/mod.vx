// std::sync - Layer 2: Synchronization (100% Safe Native Vex)
// Concurrency primitives for async Vex programs.

// Mutex for thread-safe shared state
export struct Mutex<T> {
    data: T,
    locked: bool,
}

// Create a new mutex
export fn new_mutex<T>(value: T) : Mutex<T> {
    return Mutex {
        data: value,
        locked: false,
    };
}

// Lock the mutex (async - will wait if already locked)
export fn (m: &Mutex<T>) lock() : &T {
    // In real implementation, this would use atomic operations
    // or runtime intrinsics for proper locking
    while m.locked {
        await yield(); // Yield to scheduler
    }
    
    m.locked = true;
    return &m.data;
}

// Unlock the mutex
export fn (m: &Mutex<T>) unlock() {
    m.locked = false;
}

// Channel for async communication between tasks
export struct Channel<T> {
    buffer: [T],
    capacity: i32,
}

// Create a new channel with given capacity
export fn new_channel<T>(capacity: i32) : Channel<T> {
    return Channel {
        buffer: [],
        capacity: capacity,
    };
}

// Send value to channel (blocks if full)
export fn (c: &Channel<T>) send(value: T) : (nil | error) {
    while c.buffer.len() >= c.capacity {
        await yield(); // Wait for space
    }
    
    c.buffer.push(value);
    return nil;
}

// Receive value from channel (blocks if empty)
export fn (c: &Channel<T>) recv() : (T | error) {
    while c.buffer.len() == 0 {
        await yield(); // Wait for data
    }
    
    value := c.buffer[0];
    c.buffer.remove(0);
    return value;
}

// WaitGroup for coordinating multiple async tasks
export struct WaitGroup {
    count: i32,
}

// Create new wait group
export fn new_waitgroup() : WaitGroup {
    return WaitGroup { count: 0 };
}

// Add to wait group counter
export fn (wg: &WaitGroup) add(delta: i32) {
    wg.count = wg.count + delta;
}

// Mark one task as done
export fn (wg: &WaitGroup) done() {
    wg.count = wg.count - 1;
}

// Wait until counter reaches zero
export fn (wg: &WaitGroup) wait() {
    while wg.count > 0 {
        await yield();
    }
}

// Semaphore for limiting concurrent access
export struct Semaphore {
    permits: i32,
}

// Create semaphore with N permits
export fn new_semaphore(permits: i32) : Semaphore {
    return Semaphore { permits: permits };
}

// Acquire a permit (blocks if none available)
export fn (s: &Semaphore) acquire() {
    while s.permits <= 0 {
        await yield();
    }
    s.permits = s.permits - 1;
}

// Release a permit
export fn (s: &Semaphore) release() {
    s.permits = s.permits + 1;
}

// RwLock - Multiple readers or single writer
export struct RwLock<T> {
    data: T,
    readers: i32,
    writer: bool,
}

// Create new RwLock
export fn new_rwlock<T>(value: T) : RwLock<T> {
    return RwLock {
        data: value,
        readers: 0,
        writer: false,
    };
}

// Acquire read lock
export fn (rw: &RwLock<T>) read() : &T {
    while rw.writer {
        await yield();
    }
    rw.readers = rw.readers + 1;
    return &rw.data;
}

// Release read lock
export fn (rw: &RwLock<T>) read_unlock() {
    rw.readers = rw.readers - 1;
}

// Acquire write lock
export fn (rw: &RwLock<T>) write() : &T {
    while rw.readers > 0 || rw.writer {
        await yield();
    }
    rw.writer = true;
    return &rw.data;
}

// Release write lock
export fn (rw: &RwLock<T>) write_unlock() {
    rw.writer = false;
}

// Helper: yield control to scheduler
async fn yield() {
    // This would call __runtime_yield intrinsic
    // Suspends current task and lets scheduler run others
}
